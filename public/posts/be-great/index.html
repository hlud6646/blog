<!doctype html>





































<html
  class="not-ready lg:text-base"
  style="--bg: #faf8f1"
  lang="en-us"
  dir="ltr"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    
    <title>Be GReaT - Stories and Cheat-Sheets</title>

    
    <meta name="theme-color" />

    
    
    
    
    <meta name="description" content="I came across an article (1) titled &lsquo;Language Models are Realistic Tabular Data
Generators&rsquo; which argues just that. The process is something like

Convert your tabular data into sentences;
Fine tune a large language model on those sentences;
Ask it to generate new ones.

I found this fairly interesting and decided to test the process. I might have set
my expectations too high but I got really excited about the idea of a language model
as a data-augmentation strategy.  The authors have also made their code open source
and the API is pretty straightforward." />
    <meta name="author" content="Stories and Cheat-Sheets" />
    

    
    
    
    
    
    
    <link rel="preload stylesheet" as="style" href="https://hlud6646.surge.sh/main.min.css" />

    
    <link
        rel="stylesheet"
        type="text/css"
        href="https://cdn.jsdelivr.net/npm/cm-chessboard@5.2.4/assets/styles/cm-chessboard.css"
    />

    
    
    
    
    
    <link rel="preload" as="image" href="https://hlud6646.surge.sh/theme.png" />

    
    
    
    
    

    
    
    <link rel="preload" as="image" href="https://hlud6646.surge.sh/github.svg" />
    
    <link rel="preload" as="image" href="https://hlud6646.surge.sh/linkedin.svg" />
    
    

    
    
    <script
        defer
        src="https://hlud6646.surge.sh/highlight.min.js"
        onload="hljs.initHighlightingOnLoad();"
    ></script>
    

    
    
    

    
    <link
        rel="icon"
        href="https://hlud6646.surge.sh/favicon.ico"
    />
    <link
        rel="apple-touch-icon"
        href="https://hlud6646.surge.sh/apple-touch-icon.png"
    />

    
    <meta name="generator" content="Hugo 0.139.4">

    
    
    
    
    
    
  <meta itemprop="name" content="Be GReaT">
  <meta itemprop="description" content="I came across an article (1) titled ‘Language Models are Realistic Tabular Data Generators’ which argues just that. The process is something like
Convert your tabular data into sentences; Fine tune a large language model on those sentences; Ask it to generate new ones. I found this fairly interesting and decided to test the process. I might have set my expectations too high but I got really excited about the idea of a language model as a data-augmentation strategy. The authors have also made their code open source and the API is pretty straightforward.">
  <meta itemprop="datePublished" content="2023-07-10T17:08:01+10:00">
  <meta itemprop="dateModified" content="2023-07-10T17:08:01+10:00">
  <meta itemprop="wordCount" content="315">
    
    <meta property="og:url" content="https://hlud6646.surge.sh/posts/be-great/">
  <meta property="og:site_name" content="Stories and Cheat-Sheets">
  <meta property="og:title" content="Be GReaT">
  <meta property="og:description" content="I came across an article (1) titled ‘Language Models are Realistic Tabular Data Generators’ which argues just that. The process is something like
Convert your tabular data into sentences; Fine tune a large language model on those sentences; Ask it to generate new ones. I found this fairly interesting and decided to test the process. I might have set my expectations too high but I got really excited about the idea of a language model as a data-augmentation strategy. The authors have also made their code open source and the API is pretty straightforward.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-07-10T17:08:01+10:00">
    <meta property="article:modified_time" content="2023-07-10T17:08:01+10:00">

    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Be GReaT">
  <meta name="twitter:description" content="I came across an article (1) titled ‘Language Models are Realistic Tabular Data Generators’ which argues just that. The process is something like
Convert your tabular data into sentences; Fine tune a large language model on those sentences; Ask it to generate new ones. I found this fairly interesting and decided to test the process. I might have set my expectations too high but I got really excited about the idea of a language model as a data-augmentation strategy. The authors have also made their code open source and the API is pretty straightforward.">

    
    

    
    <link rel="canonical" href="https://hlud6646.surge.sh/posts/be-great/" />
    
    
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[4.5rem] max-w-[--w] px-8 lg:justify-center">
    <div class="relative z-50 ltr:mr-auto rtl:ml-auto flex items-center">
        <a
            class="-translate-y-[1px] text-2xl font-medium"
            href="https://hlud6646.surge.sh/"
            >Stories and Cheat-Sheets</a
        >
        
        
    </div>

    <div
        class="btn-menu relative z-50 ltr:-mr-8 rtl:-ml-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
        role="button"
        aria-label="Menu"
    ></div>

    

    <script>
        
        const htmlClass = document.documentElement.classList;
        setTimeout(() => {
            htmlClass.remove("not-ready");
        }, 10);

        
        const btnMenu = document.querySelector(".btn-menu");
        btnMenu.addEventListener("click", () => {
            htmlClass.toggle("open");
        });

        
        const metaTheme = document.querySelector('meta[name="theme-color"]');
        const lightBg = "#faf8f1".replace(/"/g, "");
        const setDark = (isDark) => {
            metaTheme.setAttribute("content", isDark ? "#000" : lightBg);
            htmlClass[isDark ? "add" : "remove"]("dark");
            localStorage.setItem("dark", isDark);
        };

        
        const darkScheme = window.matchMedia("(prefers-color-scheme: dark)");
        if (htmlClass.contains("dark")) {
            setDark(true);
        } else {
            const darkVal = localStorage.getItem("dark");
            setDark(darkVal ? darkVal === "true" : darkScheme.matches);
        }

        
        darkScheme.addEventListener("change", (event) => {
            setDark(event.matches);
        });

        
        const btnDark = document.querySelector(".btn-dark");
        btnDark.addEventListener("click", () => {
            setDark(localStorage.getItem("dark") !== "true");
        });
    </script>

    <div
        class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
    >
        
        
        <nav
            class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"
        >
            
            <a
                class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
                href="/about/"
                >About</a
            >
            
            <a
                class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
                href="/contact/"
                >Contact</a
            >
            
        </nav>
        

        
        <nav
            class="mt-12 flex justify-center space-x-10 rtl:space-x-reverse dark:invert ltr:lg:ml-14 rtl:lg:mr-14 lg:mt-0 lg:items-center"
        >
            
            <a
                class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
                style="--url: url(./github.svg)"
                href="https://github.com/hlud6646"
                target="_blank"
                rel="me"
            >
                github
            </a>
            
            <a
                class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
                style="--url: url(./linkedin.svg)"
                href="https://linkedin.com/in/hugoludemann"
                target="_blank"
                rel="me"
            >
                linkedin
            </a>
            
        </nav>
        
    </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100vh-9rem)] max-w-[--w] px-8 pb-16 pt-14 dark:prose-invert"
    >
      

<article>
    <header class="mb-14">
        <h1 class="!my-0 pb-2.5">Be GReaT</h1>

        
        <div class="text-xs antialiased opacity-60">
            
            <time>Jul 10, 2023</time>
            
            
            
            
        </div>
        
    </header>

    
    

    <section><p>I came across an article (1) titled &lsquo;Language Models are Realistic Tabular Data
Generators&rsquo; which argues just that. The process is something like</p>
<ol>
<li>Convert your tabular data into sentences;</li>
<li>Fine tune a large language model on those sentences;</li>
<li>Ask it to generate new ones.</li>
</ol>
<p>I found this fairly interesting and decided to test the process. I might have set
my expectations too high but I got really excited about the idea of a language model
as a data-augmentation strategy.  The authors have also made their code open source
and the API is pretty straightforward.</p>
<p>For my experiment I loaded the abalone dataset, which contains the sex and spatial and weight
measurements of ~4000 snails. 1000 samples are set aside for validation data (although as
we never even get to use it.)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data <span style="color:#f92672">=</span> fetch_openml(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;abalone&#39;</span>, version<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, parser<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;auto&#34;</span>)
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>x[<span style="color:#e6db74">&#39;Sex&#39;</span>] <span style="color:#f92672">=</span> x[<span style="color:#e6db74">&#39;Sex&#39;</span>]<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;category&#39;</span>)<span style="color:#f92672">.</span>cat<span style="color:#f92672">.</span>codes <span style="color:#75715e"># label encoding.</span>
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>target<span style="color:#f92672">.</span>astype(float)
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> x
</span></span><span style="display:flex;"><span>data[<span style="color:#e6db74">&#39;Rings&#39;</span>] <span style="color:#f92672">=</span> y
</span></span><span style="display:flex;"><span>data_train, data_test <span style="color:#f92672">=</span> train_test_split(data, train_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3000</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">420</span>)
</span></span></code></pre></div><p>The plan is to train and validate a regression model on the original data, then on
a dataset containing the original 3000 samples augmented by the same number of synthetic
samples. Hopefully the model trained on the extra data will have greater predictive power
on unseen data.  As mentioned, the API is simple:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>great <span style="color:#f92672">=</span> be_great<span style="color:#f92672">.</span>GReaT(<span style="color:#e6db74">&#34;distilgpt2&#34;</span>,
</span></span><span style="display:flex;"><span>                       epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, 
</span></span><span style="display:flex;"><span>                       save_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">2000</span>,
</span></span><span style="display:flex;"><span>                       logging_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>,
</span></span><span style="display:flex;"><span>                       experiment_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trainer_abalone&#34;</span>,
</span></span><span style="display:flex;"><span>                       batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>)
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> great<span style="color:#f92672">.</span>fit(data_train)
</span></span><span style="display:flex;"><span>synthetic_data <span style="color:#f92672">=</span> great<span style="color:#f92672">.</span>sample(<span style="color:#ae81ff">3000</span>)
</span></span></code></pre></div><p>Unfortunately the univariate densities are pretty terrible imitations of the
originals though, so bad that I&rsquo;m calling it quits here. Maybe a larger model
would do better but actually now I think I must have been dreaming if I thought
this could be used for meaningful data augmentation!</p>
<p><img src="./images/kde.png" alt="kde plot"></p>
<p>Even though this didn&rsquo;t really work it&rsquo;s been fun to play with an experimental
library and maybe it could be useful for other things, like generating a big
dataset for development purposes before the real one becomes available.</p>
<p>Refs:</p>
<ol>
<li><a href="https://openreview.net/pdf?id=cEygmQNOeI">https://openreview.net/pdf?id=cEygmQNOeI</a></li>
</ol>
</section>

    
    
    
    
    <nav
        class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg !leading-[1.2] *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"
    >
        
        <a class="ltr:pr-3 rtl:pl-3" href="https://hlud6646.surge.sh/posts/groups_william/"
            ><span class="ltr:mr-1.5 rtl:ml-1.5">←</span
            ><span>Dihedral Group of order 3 for 13 Year-olds</span></a
        >
        
        
        <a
            class="ltr:ml-auto rtl:mr-auto justify-end pl-3"
            href="https://hlud6646.surge.sh/posts/generating_functions/"
            ><span>Generating Functions</span
            ><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a
        >
        
    </nav>
    
    

    
    

    
    

    


    
</article>


    </main>

    <footer
    class="mx-auto flex h-[4.5rem] max-w-[--w] items-center px-8 text-xs uppercase tracking-wider opacity-60"
>
    <div class="mr-auto">
         &copy; 2025
        <a class="link" href="https://hlud6646.surge.sh/">Stories and Cheat-Sheets</a>
        
    </div>
    
</footer>

  </body>
</html>
